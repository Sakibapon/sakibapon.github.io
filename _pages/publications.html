<!-- ======= Research Papers Section ======= -->
<section id="services" class="services">
    <div class="container">

      <div class="section-title">
        <h2>Publications</h2>
      </div>

      <div class="row">
        <div class="col" data-aos="fade-up">
          <div class="icon"><i class="icofont-computer"></i></div>
          <h4 class="title"><a href="https://ieeexplore.ieee.org/document/9608407">Realtime Action Recogniction</a></h4>
          
          <p class="description"><strong>Authors: </strong><strong style="color: #149ddd;">Tasnim Sakib Apon</strong>, Mushfiqul Islam Chowdhury, Md Zubair Reza, Arpita Datta, Syeda Tanjina Hasan, Md. Golam Rabiul Alam</p>
          
          <p class="description"><strong>Abstract : </strong>Crime rate is increasing proportionally with the increasing rate of the population. The most prominent approach was to introduce 
            Closed-Circuit Television (CCTV) camera-based surveillance to tackle the issue. Video surveillance cameras have added a new dimension to detect crime. Several research works on 
            autonomous security camera surveillance are currently ongoing, where the fundamental goal is to discover violent activity from video feeds. From the technical viewpoint, this i
            s a challenging problem because analyzing a set of frames, i.e., videos in temporal dimension to detect violence might need careful machine learning model training to reduce 
            false results. This research focused on this problem by integrating state-of-the-art Deep Learning methods to ensure a robust pipeline for autonomous surveillance for detecting 
            violent activities, e.g., kicking, punching, and slapping. Initially, we designed a dataset of this specific interest, which were 600 videos (200 for each action). Later, 
            we have utilized existing pre-trained model architectures to extract features, followed by classification and accuracy analysis.Also, We have classified our models' accuracy, 
            and confusion matrix on different pre-trained architectures like VGG16, InceptionV3, ResNet50, Xception and MobileNet V2. Among the pre-trained models VGG16 and MobileNet V2 
            performed better.</p>
          <p class="description"><strong></strong> <a style="color: green;">Accepted</a>  @<a href="http://fse.green.edu.bd/sti-2021/?fbclid=IwAR2Oa3ATiis3Px-DMBRzHeXQ6PhxKWW9vYQ5BQMZn0HTITn0yJro-d57LZQ#intro" target="_blank"> 
            International conference on sustainable technologies for industry 4.0</a></p>
          <p class="description"><strong>View Paper - </strong><a href="https://ieeexplore.ieee.org/document/9608407" target="_blank"> IEEE Xplore </a> </p>
          
        <div style="padding: 20px;"></div>
        </div>
      </div>
      <div class="row">
        <div class="col" data-aos="fade-up">
          <div class="icon"><i class="icofont-computer"></i></div>
          <h4 class="title"><a href="https://ieeexplore.ieee.org/document/9608407">CS: GO Action Recognition and Data Collection Automation Using Transfer Learning and  Majority Voting</a></h4>
          
          <p class="description"><strong>Authors: </strong><strong style="color: #149ddd;">Tasnim Sakib Apon</strong>, Abrar Islam, Md. Golam Rabiul Alam</p>
          
          <p class="description"><strong>Abstract : </strong>Presently online video games have become a progressively favorite source of recreation and Counter Strike: Global Offensive (CS: GO) is one of the top-listed online first-person shooting games. Numerous competitive games are arranged every year by Esports. Nonetheless, (i) No study has been conducted on video analysis and action recognition of CS: GO game-play which can play a substantial role in the gaming industry for prediction model (ii) No work has been done on the real-time application on the actions and results of a CS: GO match (iii) Game data of a match is usually available in the HLTV as a CSV formatted file however it does not have open access and HLTV tends to prevent users from taking data. This manuscript aims to develop a model for accurate prediction of 4 different actions and compare the performance among the five different transfer learning models with our self-developed deep neural network and identify the best-fitted model and also including major voting later on, which is qualified to provide  real time prediction and the result of this model aids to the construction of the automated system of gathering and processing more data alongside solving the issue of collecting data from HLTV.</p>

          <p class="description"><strong></strong> <a style="color: green;">Accepted</a> @<a href="http://icts.if.its.ac.id/2021/" target="_blank"> 13th International Conference on Information & 
            Communication Technology and System</a> </p>
          <p class="description"><strong>View Paper - </strong><a href="https://ieeexplore.ieee.org/document/9608407" target="_blank"> IEEE Xplore </a> </p>

            
          <div style="padding: 20px;"></div>
        </div>
      </div>

      <div class="row">
        <div class="col" data-aos="fade-up">
          <div class="icon"><i class="icofont-computer"></i></div>
          <h4 class="title"><a href="https://ieeexplore.ieee.org/document/9718400">Demystifying  Deep Learning Models for Retinal OCT Disease Classification using Explainable AI</a></h4>
          
          <p class="description"><strong>Authors: </strong><strong style="color: #149ddd;">Tasnim Sakib Apon</strong>, Mohammad Mahmudul Hasan, Abrar Islam, Md. Golam Rabiul Alam</p>
          
          <p class="description"><strong>Abstract : </strong>In the world of medical diagnostics, the adoption of various deep learning techniques is quite common as well as effective, and its statement is equally true when it comes to implementing it into the retina Optical Coherence Tomography (OCT) sector,  but (i)These techniques have the black box characteristics that prevent the medical professionals to completely trust the results generated from them  (ii)Lack of precision of these methods restricts their implementation in clinical and complex cases (iii)The existing works and models on the OCT classification are substantially large and complicated and they require a considerable amount of memory and computational power, reducing the quality of classifiers in real-time applications. To meet these problems, in this paper a self-developed CNN model has been proposed which is comparatively smaller and simpler along with the use of Lime that introduces Explainable AI to the study and helps to increase the interpretability of the model. This addition will be an asset to the medical experts for getting major and detailed information and will help them in making final decisions and will also reduce the opacity and vulnerability of the conventional deep learning models. </p>

          <p class="description"><strong></strong> <a style="color: green;">Accepted</a> @ <a href="https://ieee-csde.org/2021/" target="_blank">8th IEEE Asia Pacific Conference on Computer Science 
            and Data Engineering </a></p>
          <p class="description"><strong>View Paper - </strong><a href="https://ieeexplore.ieee.org/document/9718400" target="_blank"> IEEE Xplore </a> </p>
          <div style="padding: 20px;"></div>
        </div>
      </div>
    </div>

  </section><!-- End Services Section -->